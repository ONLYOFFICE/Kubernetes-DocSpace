# Default values for DocSpace

# DocSpace common parameters
# This block defines common parameters for all DocSpace Apps services
#
# Connection parameters to services
connections:
  # connections.envExtension Defines whether an environment will be used
  envExtension: "none"
  # connections.installationType Defines solution type
  installationType: COMMUNITY
  # connections.migrationType Defines migration type
  migrationType: STANDALONE
  # connections.mysqlDatabaseMigration Enables database migration
  mysqlDatabaseMigration: "false"
  # connections.mysqlHost The IP address or the name of the Database host
  mysqlHost: mysql
  # connections.mysqlPort Database server port number
  mysqlPort: "3306"
  # connections.mysqlDatabase Name of the Database the application will be connected with
  # The database must already exist
  mysqlDatabase: docspace
  # connections.mysqlUser Database user
  mysqlUser: onlyoffice_user
  # connections.mysqlPassword Database user password
  # If set to, it takes priority over the `connections.mysqlExistingSecret`
  mysqlPassword: ""
  # connections.mysqlExistingSecret Name of existing secret to use for Database passwords
  # Must contain the key specified in `connections.mysqlSecretKeyPassword`
  mysqlExistingSecret: mysql
  # connections.mysqlSecretKeyPassword The name of the key that contains the Database user password
  # If you set a password in `connections.mysqlPassword`, a secret will be automatically created, the key name of which will be the value set here
  mysqlSecretKeyPassword: mysql-password
  # connections.redisHost The IP address or the name of the Redis host
  # If Redis is deployed inside a k8s cluster, then you need to specify the FQDN name of the service
  # ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#services
  redisHost: redis-master.default.svc.cluster.local
  # connections.redisPort The Redis server port number
  redisPort: "6379"
  # connections.redisUser The Redis user name
  # ref: https://redis.io/docs/management/security/acl/
  redisUser: default
  # connections.redisExistingSecret Name of existing secret to use for Redis password
  # Must contain the key specified in `connections.redisSecretKeyName`
  redisExistingSecret: redis
  # connections.redisSecretKeyName The name of the key that contains the Redis user password
  # If you set a password in `connections.redisPassword`, a secret will be automatically created, the key name of which will be the value set here
  redisSecretKeyName: redis-password
  # connections.redisPassword The password set for the Redis account
  # If set to, it takes priority over the `connections.redisExistingSecret`
  redisPassword: ""
  # connections.redisNoPass Defines whether to use a Redis auth without a password
  # If the connection to Redis server does not require a password, set the value to `true`
  redisNoPass: false
  # connections.brokerHost The IP address or the name of the Broker host
  brokerHost: rabbitmq
  # connections.brokerPort The port for the connection to Broker host
  brokerPort: "5672"
  # connections.brokerVhost The virtual host for the connection to Broker host
  brokerVhost: "/"
  # connections.brokerUser The username for the Broker account
  brokerUser: user
  # connections.brokerProto The protocol for the connection to Broker host
  brokerProto: amqp
  # connections.brokerUri A string containing the necessary connection parameters to Broker
  # If set to, it takes priority
  brokerUri: ""
  # connections.brokerExistingSecret The name of existing secret to use for Broker password
  # Must contain the key specified in `connections.brokerSecretKeyName`
  brokerExistingSecret: rabbitmq
  # connections.brokerSecretKeyName The name of the key that contains the Broker user password
  # If you set a password in `connections.brokerPassword`, a secret will be automatically created, the key name of which will be the value set here
  brokerSecretKeyName: rabbitmq-password
  # connections.brokerPassword Broker user password
  # If set to, it takes priority over the `connections.brokerExistingSecret`
  brokerPassword: ""
  # connections.elkSheme The protocol for the connection to Opensearch
  elkSheme: http
  # connections.elkHost The IP address or the name of the Opensearch host
  elkHost: opensearch
  # connections.elkPort The port for the connection to Opensearch
  elkPort: "9200"
  # connections.elkThreads Number of threads in Opensearch
  elkThreads: "1"
  # connections.apiHost The name of the DocSpace Api service
  apiHost: api
  # connections.apiSystemHost The name of the DocSpace Api System service
  apiSystemHost: api-system
  # connections.notifyHost The name of the DocSpace Notify service
  notifyHost: notify
  # connections.studioNotifyHost The name of the DocSpace Studio Notify service
  studioNotifyHost: studio-notify
  # connections.socketHost The name of the DocSpace Socket service
  socketHost: socket
  # connections.peopleServerHost The name of the DocSpace People Server service
  peopleServerHost: people-server
  # connections.filesHost The name of the DocSpace Files service
  filesHost: files
  # connections.filesServicesHost The name of the DocSpace Files Services service
  filesServicesHost: files-services
  # connections.studioHost The name of the DocSpace Studio service
  studioHost: studio
  # connections.backupHost The name of the DocSpace Backup service
  backupHost: backup
  # connections.ssoauthHost The name of the DocSpace SSO service
  ssoauthHost: ssoauth
  # connections.clearEventsHost The name of the DocSpace Clear Events service
  clearEventsHost: clear-events
  # connections.doceditorHost The name of the DocSpace Doceditor service
  doceditorHost: doceditor
  # connections.backupBackgroundTasksHost The name of the DocSpace Backup Background Tasks service
  backupBackgroundTasksHost: backup-background-tasks
  # connections.loginHost The name of the DocSpace Login service
  loginHost: login
  # connections.healthchecksHost The name of the DocSpace Healthchecks service
  healthchecksHost: healthchecks
  # connections.dashboardsHost The name of the DocSpace Dashboards service
  dashboardsHost: dashboards
  # connections.documentServerHost The name of the Document Server service
  # Used when installing a local Document Server (by default `docs.enabled=true`)
  documentServerHost: document-server
  # connections.documentServerUrlExternal The address of the external Document Server
  # If set, the local Document Server will not be installed
  # The address must be in the `http(s)://<documentserver-address>/` format
  documentServerUrlExternal: ""
  # connections.appUrlPortal URL for DocSpace requests
  # By default, the name of the routing (Router) service and the port on which it accepts requests are used
  appUrlPortal: "http://router:8092"
  # connections.appCoreBaseDomain The base domain on which the DocSpace will be available
  appCoreBaseDomain: localhost
  appCoreMachinekey:
    # connections.appCoreMachinekey.secretKey The secret key used in the DocSpace
    secretKey: "your_core_machinekey"
    # connections.appCoreMachinekey.existingSecret The name of an existing secret containing Core Machine Key
    # Must contain the `APP_CORE_MACHINEKEY` key
    # If not specified, a secret will be created with the value set in `connections.appCoreMachinekey.secretKey`
    existingSecret: ""
  # connections.countWorkerConnections Defines the nginx config worker_connections directive for routing (Router) service
  # ref: https://nginx.org/en/docs/ngx_core_module.html#worker_connections
  countWorkerConnections: "1024"
  # connections.nginxSnvsubstTemplateSuffix A suffix of template files for rendering nginx configs in routing (Router) service
  nginxSnvsubstTemplateSuffix: ".template"
  # connections.wrongPortalNameURL
  wrongPortalNameURL: ""
  # connections.appKnownNetworks Defines the address ranges of known networks to accept forwarded headers from for DocSpace services
  # In particular, the networks in which the proxies that you are using in front of DocSpace services are located should be indicated here
  # Provide IP ranges using CIDR notation
  # Example:
  # appKnownNetworks: "10.244.0.0/16,10.245.0.0/16"
  appKnownNetworks: "10.244.0.0/16"
  # connections.appKnownProxies Deprecated parameter. Use `connections.appKnownNetworks` instead
  appKnownProxies: ""
  # connections.oauthRedirectURL Address of the oauth authorization server
  oauthRedirectURL: "https://service.onlyoffice.com/oauth2.aspx"
# namespaceOverride The name of the namespace in which DocSpace will be deployed
# If not set, the name will be taken from .Release.Namespace
namespaceOverride: ""
# commonLabels Defines labels that will be additionally added to all the deployed resources
# You can also use `tpl` as the value for the key
# ref: https://helm.sh/docs/chart_best_practices/labels/
# Example:
# commonLabels:
#   app.kubernetes.io/name: "{{ .Chart.Name }}"
#   helm.sh/chart: '{{ .Chart.Name }}-{{ .Chart.Version | replace "+" "_" }}'
#   app.kubernetes.io/managed-by: "{{ .Release.Service }}"
#   app.kubernetes.io/instance: "{{ .Release.Name }}"
#   app.kubernetes.io/version: "{{ .Chart.AppVersion }}"
commonLabels: {}
# podAnnotations Map of annotations to add to the DocSpace pods
podAnnotations:
  rollme: "{{ randAlphaNum 5 | quote }}"
# Service account parameters
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
serviceAccount:
  # serviceAccount.create Enable ServiceAccount creation
  create: false
  # serviceAccount.name Name of the ServiceAccount to be used
  # If not set and `serviceAccount.create` is `true` the name will be taken from .Release.Name
  # If not set and `serviceAccount.create` is `false` the name will be "default"
  name: ""
  # serviceAccount.annotations Map of annotations to add to the ServiceAccount
  annotations: {}
  # serviceAccount.automountServiceAccountToken Enable auto mount of ServiceAccountToken on the serviceAccount created
  # Used only if `serviceAccount.create` is `true`
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#opt-out-of-api-credential-automounting
  automountServiceAccountToken: true
# Configure a Security Context for the DocSpace application Pods
# Each Docspace application can override the values specified here with its own
# Individual values for `docs` and `elasticsearch`
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
podSecurityContext:
  # podSecurityContext.enabled Enable security context for the pods
  # If set to true, `podSecurityContext` is enabled for all resources describing the podTemplate
  enabled: false
  # podSecurityContext.fsGroup Defines the Group ID to which the owner and permissions for all files in volumes are changed when mounted in the DocSpace application Pods
  fsGroup: 107
# Configure a Security Context for containers in DocSpace application Pods
# Each Docspace application can override the values specified here with its own
# Individual values for `docs` and `elasticsearch`
containerSecurityContext:
  # containerSecurityContext.enabled Enable security context for containers in DocSpace application pods
  enabled: false
  # containerSecurityContext.runAsUser User ID for the DocSpace application containers
  runAsUser: 104
  # containerSecurityContext.runAsGroup Group ID for the DocSpace application containers
  runAsGroup: 107
  # containerSecurityContext.runAsNonRoot Require that the container will run with a user with UID other than 0
  runAsNonRoot: true
  # containerSecurityContext.allowPrivilegeEscalation Controls whether a process can gain more privileges than its parent process
  allowPrivilegeEscalation: false
  # containerSecurityContext.seLinuxOptions Defines SELinux labels for the DocSpace application containers
  seLinuxOptions: {}
  # containerSecurityContext.seccompProfile Defines the Seccomp profile for the DocSpace application containers
  seccompProfile:
    type: RuntimeDefault
  # containerSecurityContext.capabilities Defines the privileges granted to the process
  capabilities:
    drop: ["ALL"]
# nodeSelector Node labels for DocSpace application pods assignment
# Each Docspace application can override the values specified here with its own
# ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
nodeSelector: {}
# tolerations Tolerations for DocSpace application pods assignment
# Each Docspace application can override the values specified here with its own
# ref: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
tolerations: []
# imagePullSecrets Container image registry secret name
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: ""
# Global image parameters for for all DocSpace applications
# Does not apply to the Document Server, Elasticsearch and Proxy Frontend
images:
  # images.repoPrefix Global repository prefix for all DocSpace applications
  repoPrefix: ""
  # images.tag Global image tag for all DocSpace applications
  # Does not apply to the Document Server and Elasticsearch
  tag: 2.5.0
# JSON Web Token parameters
jwt:
  # jwt.enabled Specifies the enabling the JSON Web Token validation by the DocSpace
  enabled: true
  # jwt.secret Defines the secret key to validate the JSON Web Token in the request to the DocSpace
  secret: "jwt_secret"
  # jwt.header Defines the http header that will be used to send the JSON Web Token
  header: "AuthorizationJwt"
  # jwt.inBody Specifies the enabling the token validation in the request body to the DocSpace
  inBody: false
  # jwt.existingSecret The name of an existing secret containing variables for jwt
  # If not specified, a secret named `jwt` will be created
  existingSecret: ""
# Configs for overriding default values and additional configuration files for DocSpace
extraConf:
  # extraConf.secretName The name of the Secret containing the json files that override the default values and additional configuration files
  secretName: ""
  # extraConf.filename The name of the json files that contains custom values and name additional configuration files
  # Must be the same as the `key` name in `extraConf.secretName`
  # May contain multiple values
  fileName:
    - appsettings.test.json
# log.level Defines the type and severity of a logged event
log:
  level: "Warning"
# debug.enabled Enable debug
debug:
  enabled: "false"
# DocSpace Init Containers parameters
# Containers that run before containers in a Pods
# ref:https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
initContainers:
  # Parameters of the Check DB initContainers
  checkDB:
    image:
      # initContainers.checkDB.image.repository check-db initContainer image repository
      repository: mysql
      # initContainers.checkDB.image.tag check-db initContainer image tag
      tag: latest
      # initContainers.checkDB.image.pullPolicy check-db initContainer image pull policy
      pullPolicy: IfNotPresent
    # check-db initContainer resource requests and limits
    # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    # initContainers.checkDB.resources.requests The requested resources for the check-db initContainer
    # initContainers.checkDB.resources.limits The resources limits for the check-db initContainer
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "1000m"
  # Parameters of the Wait Storage initContainers
  waitStorage:
    image:
      # initContainers.waitStorage.image.repository app-wait-storage initContainer image repository
      repository: onlyoffice/docspace-wait-bin-share
      # initContainers.waitStorage.image.tag app-wait-storage initContainer image tag
      # If set to, it takes priority over the `images.tag`
      tag: ""
      # initContainers.waitStorage.image.pullPolicy app-wait-storage initContainer image pull policy
      pullPolicy: IfNotPresent
    # app-wait-storage initContainer resource requests and limits
    # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    # initContainers.waitStorage.resources.requests The requested resources for the app-wait-storage initContainer
    # initContainers.waitStorage.resources.limits The resources limits for the app-wait-storage initContainer
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "1000m"
  # Parameters of the Init Storage initContainers
  initStorage:
    image:
      # initContainers.initStorage.image.repository app-init-storage initContainer image repository
      repository: onlyoffice/docspace-bin-share
      # initContainers.initStorage.image.tag app-init-storage initContainer image tag
      # If set to, it takes priority over the `images.tag`
      tag: ""
      # initContainers.initStorage.image.pullPolicy app-init-storage initContainer image pull policy
      pullPolicy: IfNotPresent
    # app-init-storage initContainer resource requests and limits
    # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    # initContainers.initStorage.resources.requests The requested resources for the app-init-storage initContainer
    # initContainers.initStorage.resources.limits The resources limits for the app-init-storage initContainer
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
  # initContainers.custom Custom initContainers parameters
  # Does not apply to the following services: `Docs`, `Router`, `Opensearch` and `Proxy Frontend`. The corresponding individual parameters are used for them
  # Example:
  # custom:
  #   - name: additional-init-container
  #     image: busybox:latest
  #     command: ['chown', '-R', '104:107', '/app/onlyoffice/data']
  #     volumeMounts:
  #     - name: docspace-data
  #       mountPath: /app/onlyoffice/data
  custom: []
# DocSpace persistence parameters
persistence:
  # persistence.storageClass PVC Storage Class for DocSpace data volume
  storageClass: "nfs"
  docspaceData:
    # persistence.docspaceData.existingClaim The name of the existing PVC for storing files common to all services
    # If not specified, a PVC named "docspace-data" will be created
    existingClaim: ""
    # persistence.docspaceData.size PVC Storage Request for common files volume
    size: 8Gi
  filesData:
    # persistence.filesData.existingClaim The name of the existing PVC for use in the Files service
    # If not specified, a PVC named "files-data" will be created
    existingClaim: ""
    # persistence.filesData.size PVC Storage Request for Files volume
    size: 2Gi
  peopleData:
    # persistence.peopleData.existingClaim The name of the existing PVC for use in the People Server service
    # If not specified, a PVC named "people-data" will be created
    existingClaim: ""
    # persistence.peopleData.size PVC Storage Request for People Server volume
    size: 2Gi
  routerLog:
    # persistence.routerLog.existingClaim The name of the existing PVC for storing Nginx logs of the Router service
    # If not specified, a PVC named "router-log" will be created
    existingClaim: ""
    # persistence.routerLog.size PVC Storage Request for Nginx logs volume
    size: 5Gi
# Pod anti-affinity parameters
# Pod anti-affinity prohibits at all (required) or, if possible (preferred), placing a second pod with the same label on the same node
# Does not apply to `Docs` and `Opensearch`
# ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
podAntiAffinity:
  # podAntiAffinity.type Types of Pod antiaffinity. Allowed values: `preferred` or `required`
  type: "preferred"
  # podAntiAffinity.topologyKey Node label key to match
  topologyKey: kubernetes.io/hostname
  # podAntiAffinity.weight Priority when selecting node. It is in the range from 1 to 100. Used only when `podAntiAffinity.type=preferred`
  weight: "100"

# DocSpace Files application parameters
# This block defines the parameters common to all the Pods of this application
#
files:
  # files.enabled Enables Files installation
  enabled: true
  # files.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # files.replicaCount Number of Files replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # files.updateStrategy.type Files update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `files.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `files.kind` is set to `Deployment`
    type: RollingUpdate
    # files.updateStrategy.rollingUpdate Used only when `files.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # files.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Files Pods unavailable during the update process
      maxUnavailable: 25%
      # files.updateStrategy.rollingUpdate.maxSurge Maximum number of Files Pods created over the desired number of Pods
      maxSurge: 25%
  # files.podManagementPolicy The Files Pods scaling operations policy
  # Used if `files.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Files Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # files.podSecurityContext.enabled Enable security context for the Files pods
    enabled: false
  # files.customPodAntiAffinity Prohibiting the scheduling of Files Pods relative to other Pods containing the specified labels on the same node
  # Example:
  # customPodAntiAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #   - labelSelector:
  #       matchExpressions:
  #       - key: app
  #         operator: In
  #         values:
  #         - files-services
  #     topologyKey: kubernetes.io/hostname
  customPodAntiAffinity: {}
  # Pod affinity rules for Files Pods scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Files Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #   - labelSelector:
  #       matchExpressions:
  #       - key: app
  #         operator: In
  #         values:
  #         - store
  #     topologyKey: topology.kubernetes.io/zone
  podAffinity: {}
  # Node affinity rules for Files Pods scheduling by nodes
  # Node affinity allow you to constrain which nodes Files Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     nodeSelectorTerms:
  #     - matchExpressions:
  #       - key: topology.kubernetes.io/zone
  #         operator: In
  #         values:
  #         - zone1
  #         - zone2
  nodeAffinity: {}
  # files.nodeSelector Node labels for Files pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # files.tolerations Tolerations for Files pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Files container image parameters
  image:
    # files.image.repository files container image repository
    repository: onlyoffice/docspace-files
    # files.image.tag files container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # files.image.pullPolicy files container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Files Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # files.containerSecurityContext.enabled Enable security context for containers in Files pods
    enabled: false
  # files.containerPorts.app files container port
  containerPorts:
    app: 5050
  # Probe used for the files container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `files.startupProbe.enabled=true`
  startupProbe:
    # files.startupProbe.enabled Enable startupProbe for files container
    enabled: true
    httpGet:
      # files.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # files.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # files.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # files.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `files.readinessProbe.enabled=true`
  readinessProbe:
    # files.readinessProbe.enabled Enable readinessProbe for files container
    enabled: true
    # files.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # files.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # files.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # files.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 20
    # files.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # files.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `files.livenessProbe.enabled=true`
  livenessProbe:
    # files.livenessProbe.enabled Enable livenessProbe for files container
    enabled: true
    # files.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # files.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # files.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # files.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 20
    # files.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # files.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # files container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # files.resources.requests The requested resources for the files container
  # files.resources.limits The resources limits for the files container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "4Gi"
      cpu: "4000m"
  # files.mysqlUser Database user who will be used by the Files service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace People Server application parameters
# This block defines the parameters common to all the Pods of this application
#
peopleServer:
  # peopleServer.enabled Enables People Server installation
  enabled: true
  # peopleServer.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # peopleServer.replicaCount Number of People Server replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # peopleServer.updateStrategy.type People Server update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `peopleServer.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `peopleServer.kind` is set to `Deployment`
    type: RollingUpdate
    # peopleServer.updateStrategy.rollingUpdate Used only when `peopleServer.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # peopleServer.updateStrategy.rollingUpdate.maxUnavailable Maximum number of People Server Pods unavailable during the update process
      maxUnavailable: 25%
      # peopleServer.updateStrategy.rollingUpdate.maxSurge Maximum number of People Server Pods created over the desired number of Pods
      maxSurge: 25%
  # peopleServer.podManagementPolicy The People Server Pods scaling operations policy
  # Used if `peopleServer.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the People Server Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # peopleServer.podSecurityContext.enabled Enable security context for the People Server pods
    enabled: false
  # peopleServer.customPodAntiAffinity Prohibiting the scheduling of People Server Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for People Server Pods scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes People Server Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #   - labelSelector:
  #       matchExpressions:
  #       - key: app
  #         operator: In
  #         values:
  #         - store
  #     topologyKey: topology.kubernetes.io/zone
  podAffinity: {}
  # Node affinity rules for People Server Pods scheduling by nodes
  # Node affinity allow you to constrain which nodes People Server Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     nodeSelectorTerms:
  #     - matchExpressions:
  #       - key: topology.kubernetes.io/zone
  #         operator: In
  #         values:
  #         - zone1
  #         - zone2
  nodeAffinity: {}
  # peopleServer.nodeSelector Node labels for People Server pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # peopleServer.tolerations Tolerations for People Server pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # People Server container image parameters
  image:
    # peopleServer.image.repository People Server container image repository
    repository: onlyoffice/docspace-people-server
    # peopleServer.image.tag People Server container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # peopleServer.image.pullPolicy People Server container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in People Server Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # peopleServer.containerSecurityContext.enabled Enable security context for containers in People Server pods
    enabled: false
  # peopleServer.containerPorts.app People Server container port
  containerPorts:
    app: 5050
  # Probe used for the People Server container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `peopleServer.startupProbe.enabled=true`
  startupProbe:
    # peopleServer.startupProbe.enabled Enable startupProbe for People Server container
    enabled: true
    httpGet:
      # peopleServer.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # peopleServer.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # peopleServer.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # peopleServer.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `peopleServer.readinessProbe.enabled=true`
  readinessProbe:
    # peopleServer.readinessProbe.enabled Enable readinessProbe for People Server container
    enabled: true
    # peopleServer.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # peopleServer.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # peopleServer.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # peopleServer.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # peopleServer.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # peopleServer.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `peopleServer.livenessProbe.enabled=true`
  livenessProbe:
    # peopleServer.livenessProbe.enabled Enable livenessProbe for People Server container
    enabled: true
    # peopleServer.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # peopleServer.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # peopleServer.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # peopleServer.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # peopleServer.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # peopleServer.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # People Server container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # peopleServer.resources.requests The requested resources for the People Server container
  # peopleServer.resources.limits The resources limits for the People Server container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # peopleServer.mysqlUser Database user who will be used by the People Server service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Router application parameters
# This block defines the parameters common to all the Pods of this application
#
router:
  # router.enabled Enables Router installation
  enabled: true
  # router.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # router.replicaCount Number of Router replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # router.updateStrategy.type Router update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `router.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `router.kind` is set to `Deployment`
    type: RollingUpdate
    # router.updateStrategy.rollingUpdate Used only when `router.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # router.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Router Pods unavailable during the update process
      maxUnavailable: 25%
      # router.updateStrategy.rollingUpdate.maxSurge Maximum number of Router Pods created over the desired number of Pods
      maxSurge: 25%
  # router.podManagementPolicy The Router Pods scaling operations policy
  # Used if `router.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Router Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # router.podSecurityContext.enabled Enable security context for the Router pods
    enabled: false
  # router.customPodAntiAffinity Prohibiting the scheduling of Router Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Router Pods scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Router Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #   - labelSelector:
  #       matchExpressions:
  #       - key: app
  #         operator: In
  #         values:
  #         - store
  #     topologyKey: topology.kubernetes.io/zone
  podAffinity: {}
  # Node affinity rules for Router Pods scheduling by nodes
  # Node affinity allow you to constrain which nodes Router Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     nodeSelectorTerms:
  #     - matchExpressions:
  #       - key: topology.kubernetes.io/zone
  #         operator: In
  #         values:
  #         - zone1
  #         - zone2
  nodeAffinity: {}
  # router.nodeSelector Node labels for Router pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # router.tolerations Tolerations for Router pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Router initContainers parameters
  # router.initContainers Containers that run before Router container in a Pod
  # ref:https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  # Example:
  # initContainers:
  #   - name: custom-init-container
  #     image: busybox:latest
  #     command: ['sh', '-c', 'sleep 180']
  initContainers: []
  # Router container image parameters
  image:
    # router.image.repository Router container image repository
    repository: onlyoffice/docspace-router
    # router.image.tag Router container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # router.image.pullPolicy Router container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Router Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # router.containerSecurityContext.enabled Enable security context for containers in Router pods
    enabled: false
  # router.containerPorts.external Router container port
  containerPorts:
    external: 8092
  # Probe used for the Router container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `router.startupProbe.enabled=true`
  startupProbe:
    # router.startupProbe.enabled Enable startupProbe for Router container
    enabled: true
    httpGet:
      # router.startupProbe.httpGet.path Checking the path for startupProbe
      path: /
      # router.startupProbe.httpGet.port Checking the port for startupProbe
      port: 8092
    # router.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # router.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `router.readinessProbe.enabled=true`
  readinessProbe:
    # router.readinessProbe.enabled Enable readinessProbe for Router container
    enabled: true
    # router.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # router.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /
      # router.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 8092
    # router.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 20
    # router.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # router.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `router.livenessProbe.enabled=true`
  livenessProbe:
    # router.livenessProbe.enabled Enable livenessProbe for Router container
    enabled: true
    # router.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 5
    httpGet:
      # router.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /
      # router.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 8092
    # router.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 20
    # router.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # router.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Router container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # router.resources.requests The requested resources for the Router container
  # router.resources.limits The resources limits for the Router container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # Additional configuration files for Router
  extraConf:
    initScripts:
      # router.extraConf.initScripts.configMap The name of the ConfigMap containing initialization scripts
      configMap: router-init-scripts
      # router.extraConf.initScripts.fileName The names of scripts containing initialization scripts
      # The values set here are necessary for correct Router configuration. You don't need to change it
      fileName:
        - 50-change-router-onlyoffice-conf.sh
    customInitScripts:
      # router.extraConf.customInitScripts.configMap The name of the ConfigMap containing custom initialization scripts
      configMap: ""
      # router.extraConf.customInitScripts.fileName The names of scripts containing custom initialization scripts
      # Must be the same as the `key` names in `router.extraConf.customInitScripts.configMap`
      # May contain multiple values
      fileName:
        - 60-custom-init-scripts.sh
    templates:
      # router.extraConf.templates.configMap The name of the ConfigMap containing configuration file templates containing environment variables
      # The values of these variables will be substituted when the container is started
      configMap: ""
      # router.extraConf.templates.fileName The names of the configuration file templates containing environment variables
      # Must be the same as the `key` names in `router.extraConf.templates.configMap`
      # May contain multiple values
      fileName:
        - 10.example.conf.template
    confd:
      # router.extraConf.confd.configMap The name of the ConfigMap containing additional custom configuration files
      # These files will be map in the `/etc/nginx/conf.d/` directory of the container
      configMap: ""
      # router.extraConf.confd.fileName The names of the configuration files containing custom configuration files
      # Must be the same as the `key` names in `router.extraConf.confd.configMap`
      # May contain multiple values
      fileName:
        - example.conf
  # Router service parameters
  service:
    # router.service.existing The name of an existing service for Router. If not set, a service named `router` will be created
    # ref: https://github.com/ONLYOFFICE/Kubernetes-DocSpace/blob/master/templates/services/router.yaml
    existing: ""
    # router.service.annotations Map of annotations to add to the Router service
    annotations: {}
    port:
      # router.service.port.external Router service port
      external: 8092
    # router.service.type Router service type
    type: ClusterIP
    # router.service.sessionAffinity Session Affinity for Router service
    # If not set, `None` will be set as the default value
    # ref: https://kubernetes.io/docs/reference/networking/virtual-ips/#session-affinity
    sessionAffinity: ""
    # router.service.sessionAffinityConfig Configuration for Router service Session Affinity
    # Used if the `router.service.sessionAffinity` is set
    # ref: https://kubernetes.io/docs/reference/networking/virtual-ips/#session-stickiness-timeout
    # Example:
    # sessionAffinityConfig:
    #   clientIP:
    #     timeoutSeconds: 900
    sessionAffinityConfig: {}
    # router.service.externalTrafficPolicy Enable preservation of the client source IP
    # There are two available options: `Cluster` (default) and `Local`
    # ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    # Not supported for service type - `ClusterIP`
    # ref: https://kubernetes.io/docs/tutorials/services/source-ip/
    externalTrafficPolicy: ""
  # Router openresty resolver
  # ref: https://github.com/openresty/openresty/#resolvconf-parsing
  resolver:
    # router.resolver.dns Configures name server used to resolve names of upstream servers into addresses
    # If set to, it takes priority over the `router.resolver.local`
    dns: ""
    # router.resolver.local Allows you to use the DNS configuration of the container
    # If set to `on`, the standard path "/etc/resolv.conf" will be used. You can specify an arbitrary path
    # Example:
    # local: "/tmp/resolv.conf"
    local: "on"

# DocSpace Healthchecks application parameters
# This block defines the parameters common to all the Pods of this application
#
healthchecks:
  # healthchecks.enabled Enables Healthchecks installation
  enabled: true
  # healthchecks.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # healthchecks.replicaCount Number of Healthchecks replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # healthchecks.updateStrategy.type Healthchecks update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `healthchecks.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `healthchecks.kind` is set to `Deployment`
    type: RollingUpdate
    # healthchecks.updateStrategy.rollingUpdate Used only when `healthchecks.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # healthchecks.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Healthchecks Pods unavailable during the update process
      maxUnavailable: 25%
      # healthchecks.updateStrategy.rollingUpdate.maxSurge Maximum number of Healthchecks Pods created over the desired number of Pods
      maxSurge: 25%
  # healthchecks.podManagementPolicy The Healthchecks Pods scaling operations policy
  # Used if `healthchecks.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Healthchecks Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # healthchecks.podSecurityContext.enabled Enable security context for the Healthchecks pods
    enabled: false
  # healthchecks.customPodAntiAffinity Prohibiting the scheduling of Healthchecks Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Healthchecks Pods scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Healthchecks Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #   - labelSelector:
  #       matchExpressions:
  #       - key: app
  #         operator: In
  #         values:
  #         - store
  #     topologyKey: topology.kubernetes.io/zone
  podAffinity: {}
  # Node affinity rules for Healthchecks Pods scheduling by nodes
  # Node affinity allow you to constrain which nodes Healthchecks Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     nodeSelectorTerms:
  #     - matchExpressions:
  #       - key: topology.kubernetes.io/zone
  #         operator: In
  #         values:
  #         - zone1
  #         - zone2
  nodeAffinity: {}
  # healthchecks.nodeSelector Node labels for Healthchecks pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # healthchecks.tolerations Tolerations for Healthchecks pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Healthchecks container image parameters
  image:
    # healthchecks.image.repository Healthchecks container image repository
    repository: onlyoffice/docspace-healthchecks
    # healthchecks.image.tag Healthchecks container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # healthchecks.image.pullPolicy Healthchecks container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Healthchecks Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # healthchecks.containerSecurityContext.enabled Enable security context for containers in Healthchecks pods
    enabled: false
  # healthchecks.containerPorts.healthcheck Healthchecks container port
  containerPorts:
    healthcheck: 5050
  # Probe used for the Healthchecks container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `healthchecks.startupProbe.enabled=true`
  startupProbe:
    # healthchecks.startupProbe.enabled Enable startupProbe for Healthchecks container
    enabled: true
    tcpSocket:
      # healthchecks.startupProbe.tcpSocket.port Checking the port for startupProbe
      port: 5050
    # healthchecks.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # healthchecks.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `healthchecks.readinessProbe.enabled=true`
  readinessProbe:
    # healthchecks.readinessProbe.enabled Enable readinessProbe for Healthchecks container
    enabled: true
    # healthchecks.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    tcpSocket:
      # healthchecks.readinessProbe.tcpSocket.port Checking the port for readinessProbe
      port: 5050
    # healthchecks.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 60
    # healthchecks.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # healthchecks.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `healthchecks.livenessProbe.enabled=true`
  livenessProbe:
    # healthchecks.livenessProbe.enabled Enable livenessProbe for Healthchecks container
    enabled: true
    # healthchecks.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    tcpSocket:
      # healthchecks.livenessProbe.tcpSocket.port Checking the port for livenessProbe
      port: 5050
    # healthchecks.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 60
    # healthchecks.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # healthchecks.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Healthchecks container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # healthchecks.resources.requests The requested resources for the Healthchecks container
  # healthchecks.resources.limits The resources limits for the Healthchecks container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "1Gi"
      cpu: "1000m"

# DocSpace statefulsets
#
# DocSpace Api System application parameters
# This block defines the parameters common to all the Pods of this application
#
apiSystem:
  # apiSystem.enabled Enables Api System installation
  enabled: true
  # apiSystem.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # apiSystem.replicaCount Number of Api System replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # apiSystem.updateStrategy.type Api System update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `apiSystem.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `apiSystem.kind` is set to `Deployment`
    type: RollingUpdate
    # apiSystem.updateStrategy.rollingUpdate Used only when `apiSystem.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # apiSystem.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Api System Pods unavailable during the update process
      maxUnavailable: 25%
      # apiSystem.updateStrategy.rollingUpdate.maxSurge Maximum number of Api System Pods created over the desired number of Pods
      maxSurge: 25%
  # apiSystem.podManagementPolicy The Api System Pods scaling operations policy
  # Used if `apiSystem.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Api System Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # apiSystem.podSecurityContext.enabled Enable security context for the Api System pods
    enabled: false
  # apiSystem.customPodAntiAffinity Prohibiting the scheduling of Api System Pods relative to other Pods containing the specified labels on the same node
  # Example:
  # customPodAntiAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #   - labelSelector:
  #       matchExpressions:
  #       - key: app
  #         operator: In
  #         values:
  #         - api
  #     topologyKey: kubernetes.io/hostname
  customPodAntiAffinity: {}
  # Pod affinity rules for Api System Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Api System Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Api System Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Api System Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # apiSystem.nodeSelector Node labels for Api System pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # apiSystem.tolerations Tolerations for Api System pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Api System container image parameters
  image:
    # apiSystem.image.repository Api System container image repository
    repository: onlyoffice/docspace-api-system
    # apiSystem.image.tag Api System container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # apiSystem.image.pullPolicy Api System container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Api System Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # apiSystem.containerSecurityContext.enabled Enable security context for containers in Api System pods
    enabled: false
  # apiSystem.containerPorts.app Api System container port
  containerPorts:
    app: 5050
  # Probe used for the Api System container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `apiSystem.startupProbe.enabled=true`
  startupProbe:
    # apiSystem.startupProbe.enabled Enable startupProbe for Api System container
    enabled: true
    httpGet:
      # apiSystem.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # apiSystem.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # apiSystem.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # apiSystem.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `apiSystem.readinessProbe.enabled=true`
  readinessProbe:
    # apiSystem.readinessProbe.enabled Enable readinessProbe for Api System container
    enabled: true
    # apiSystem.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # apiSystem.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # apiSystem.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # apiSystem.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # apiSystem.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # apiSystem.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `apiSystem.livenessProbe.enabled=true`
  livenessProbe:
    # apiSystem.livenessProbe.enabled Enable livenessProbe for Api System container
    enabled: true
    # apiSystem.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # apiSystem.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # apiSystem.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # apiSystem.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # apiSystem.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # apiSystem.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Api System container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # apiSystem.resources.requests The requested resources for the Api System container
  # apiSystem.resources.limits The resources limits for the Api System container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # apiSystem.mysqlUser Database user who will be used by the Api System service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Api application parameters
# This block defines the parameters common to all the Pods of this application
#
api:
  # api.enabled Enables Api installation
  enabled: true
  # api.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # api.replicaCount Number of Api replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # api.updateStrategy.type Api update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `api.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `api.kind` is set to `Deployment`
    type: RollingUpdate
    # api.updateStrategy.rollingUpdate Used only when `api.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # api.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Api Pods unavailable during the update process
      maxUnavailable: 25%
      # api.updateStrategy.rollingUpdate.maxSurge Maximum number of Api Pods created over the desired number of Pods
      maxSurge: 25%
  # api.podManagementPolicy The Api Pods scaling operations policy
  # Used if `api.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Api Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # api.podSecurityContext.enabled Enable security context for the Api pods
    enabled: false
  # api.customPodAntiAffinity Prohibiting the scheduling of Api Pods relative to other Pods containing the specified labels on the same node
  # Example:
  # customPodAntiAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #   - labelSelector:
  #       matchExpressions:
  #       - key: app
  #         operator: In
  #         values:
  #         - files
  #     topologyKey: kubernetes.io/hostname
  customPodAntiAffinity: {}
  # Pod affinity rules for Api Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Api Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Api Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Api Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # api.nodeSelector Node labels for Api pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # api.tolerations Tolerations for Api pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Api container image parameters
  image:
    # api.image.repository Api container image repository
    repository: onlyoffice/docspace-api
    # api.image.tag Api container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # api.image.pullPolicy Api container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Api Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # api.containerSecurityContext.enabled Enable security context for containers in Api pods
    enabled: false
  # api.containerPorts.app Api container port
  containerPorts:
    app: 5050
  # Probe used for the Api container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `api.startupProbe.enabled=true`
  startupProbe:
    # api.startupProbe.enabled Enable startupProbe for Api container
    enabled: true
    httpGet:
      # api.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # api.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # api.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # api.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `Api.readinessProbe.enabled=true`
  readinessProbe:
    # api.readinessProbe.enabled Enable readinessProbe for Api container
    enabled: true
    # api.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # api.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # api.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # api.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 20
    # api.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # api.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `Api.livenessProbe.enabled=true`
  livenessProbe:
    # api.livenessProbe.enabled Enable livenessProbe for Api container
    enabled: true
    # api.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # api.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # api.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # api.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 20
    # api.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # api.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Api container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # api.resources.requests The requested resources for the Api container
  # api.resources.limits The resources limits for the Api container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "4Gi"
      cpu: "4000m"
  # api.mysqlUser Database user who will be used by the Api service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Backup application parameters
# This block defines the parameters common to all the Pods of this application
#
backup:
  # backup.enabled Enables Backup installation
  enabled: true
  # backup.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # backup.replicaCount Number of Backup replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # backup.updateStrategy.type Backup update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `backup.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `backup.kind` is set to `Deployment`
    type: RollingUpdate
    # backup.updateStrategy.rollingUpdate Used only when `backup.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # backup.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Backup Pods unavailable during the update process
      maxUnavailable: 25%
      # backup.updateStrategy.rollingUpdate.maxSurge Maximum number of Backup Pods created over the desired number of Pods
      maxSurge: 25%
  # backup.podManagementPolicy The Backup Pods scaling operations policy
  # Used if `backup.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Backup Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # backup.podSecurityContext.enabled Enable security context for the Backup pods
    enabled: false
  # backup.customPodAntiAffinity Prohibiting the scheduling of Backup Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Backup Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Backup Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Backup Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes backup Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # backup.nodeSelector Node labels for Backup pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # backup.tolerations Tolerations for Backup pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Backup container image parameters
  image:
    # backup.image.repository Backup container image repository
    repository: onlyoffice/docspace-backup
    # backup.image.tag Backup container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # backup.image.pullPolicy Backup container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Backup Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # backup.containerSecurityContext.enabled Enable security context for containers in Backup pods
    enabled: false
  # backup.containerPorts.app Backup container port
  containerPorts:
    app: 5050
  # Probe used for the Backup container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `backup.startupProbe.enabled=true`
  startupProbe:
    # backup.startupProbe.enabled Enable startupProbe for Backup container
    enabled: true
    httpGet:
      # backup.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # backup.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # backup.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # backup.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `backup.readinessProbe.enabled=true`
  readinessProbe:
    # backup.readinessProbe.enabled Enable readinessProbe for Backup container
    enabled: true
    # backup.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # backup.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # backup.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # backup.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # backup.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # backup.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `backup.livenessProbe.enabled=true`
  livenessProbe:
    # backup.livenessProbe.enabled Enable livenessProbe for Backup container
    enabled: true
    # backup.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # backup.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # backup.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # backup.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # backup.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # backup.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Backup container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # backup.resources.requests The requested resources for the Backup container
  # backup.resources.limits The resources limits for the Backup container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # backup.mysqlUser Database user who will be used by the Backup service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Backup Background Tasks application parameters
# This block defines the parameters common to all the Pods of this application
#
backupBackgroundTasks:
  # backupBackgroundTasks.enabled Enables Backup Background Tasks installation
  enabled: true
  # backupBackgroundTasks.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # backupBackgroundTasks.replicaCount Number of Backup Background Tasks replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # backupBackgroundTasks.updateStrategy.type Backup Background Tasks update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `backupBackgroundTasks.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `backupBackgroundTasks.kind` is set to `Deployment`
    type: RollingUpdate
    # backupBackgroundTasks.updateStrategy.rollingUpdate Used only when `backupBackgroundTasks.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # backupBackgroundTasks.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Backup Background Tasks Pods unavailable during the update process
      maxUnavailable: 25%
      # backupBackgroundTasks.updateStrategy.rollingUpdate.maxSurge Maximum number of Backup Background Tasks Pods created over the desired number of Pods
      maxSurge: 25%
  # backupBackgroundTasks.podManagementPolicy The Backup Background Tasks Pods scaling operations policy
  # Used if `backupBackgroundTasks.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Backup Background Tasks Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # backupBackgroundTasks.podSecurityContext.enabled Enable security context for the Backup Background Tasks pods
    enabled: false
  # backupBackgroundTasks.customPodAntiAffinity Prohibiting the scheduling of Backup Background Tasks Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for backupBackgroundTasks Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Backup Background Tasks Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Backup Background Tasks Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Backup Background Tasks Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # backupBackgroundTasks.nodeSelector Node labels for Backup Background Tasks pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # backupBackgroundTasks.tolerations Tolerations for Backup Background Tasks pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Backup Background Tasks container image parameters
  image:
    # backupBackgroundTasks.image.repository Backup Background Tasks container image repository
    repository: onlyoffice/docspace-backup-background
    # backupBackgroundTasks.image.tag Backup Background Tasks container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # backupBackgroundTasks.image.pullPolicy Backup Background Tasks container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Backup Background Tasks Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # backupBackgroundTasks.containerSecurityContext.enabled Enable security context for containers in Backup Background Tasks pods
    enabled: false
  # backupBackgroundTasks.containerPorts.app Backup Background Tasks container port
  containerPorts:
    app: 5050
  # Probe used for the Backup Background Tasks container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `backupBackgroundTasks.startupProbe.enabled=true`
  startupProbe:
    # backupBackgroundTasks.startupProbe.enabled Enable startupProbe for Backup Background Tasks container
    enabled: true
    httpGet:
      # backupBackgroundTasks.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # backupBackgroundTasks.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # backupBackgroundTasks.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # backupBackgroundTasks.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `backupBackgroundTasks.readinessProbe.enabled=true`
  readinessProbe:
    # backupBackgroundTasks.readinessProbe.enabled Enable readinessProbe for Backup Background Tasks container
    enabled: true
    # backupBackgroundTasks.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # backupBackgroundTasks.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # backupBackgroundTasks.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # backupBackgroundTasks.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # backupBackgroundTasks.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # backupBackgroundTasks.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `backupBackgroundTasks.livenessProbe.enabled=true`
  livenessProbe:
    # backupBackgroundTasks.livenessProbe.enabled Enable livenessProbe for Backup Background Tasks container
    enabled: true
    # backupBackgroundTasks.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # backupBackgroundTasks.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # backupBackgroundTasks.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # backupBackgroundTasks.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # backupBackgroundTasks.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # backupBackgroundTasks.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Backup Background Tasks container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # backupBackgroundTasks.resources.requests The requested resources for the Backup Background Tasks container
  # backupBackgroundTasks.resources.limits The resources limits for the Backup Background Tasks container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # backupBackgroundTasks.mysqlUser Database user who will be used by the Backup Background Tasks service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Clear Events application parameters
# This block defines the parameters common to all the Pods of this application
#
clearEvents:
  # clearEvents.enabled Enables Clear Events installation
  enabled: true
  # clearEvents.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # clearEvents.replicaCount Number of Clear Events replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # clearEvents.updateStrategy.type Clear Events update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `clearEvents.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `clearEvents.kind` is set to `Deployment`
    type: RollingUpdate
    # clearEvents.updateStrategy.rollingUpdate Used only when `clearEvents.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # clearEvents.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Clear Events Pods unavailable during the update process
      maxUnavailable: 25%
      # clearEvents.updateStrategy.rollingUpdate.maxSurge Maximum number of Clear Events Pods created over the desired number of Pods
      maxSurge: 25%
  # clearEvents.podManagementPolicy The Clear Events Pods scaling operations policy
  # Used if `clearEvents.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Clear Events Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # clearEvents.podSecurityContext.enabled Enable security context for the Clear Events pods
    enabled: false
  # clearEvents.customPodAntiAffinity Prohibiting the scheduling of Clear Events Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Clear Events Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Clear Events Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Clear Events Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Clear Events Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # clearEvents.nodeSelector Node labels for Clear Events pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # clearEvents.tolerations Tolerations for Clear Events pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Clear Events container image parameters
  image:
    # clearEvents.image.repository Clear Events container image repository
    repository: onlyoffice/docspace-clear-events
    # clearEvents.image.tag Clear Events container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # clearEvents.image.pullPolicy Clear Events container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Clear Events Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # clearEvents.containerSecurityContext.enabled Enable security context for containers in Clear Events pods
    enabled: false
  # clearEvents.containerPorts.app Clear Events container port
  containerPorts:
    app: 5050
  # Probe used for the Clear Events container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `clearEvents.startupProbe.enabled=true`
  startupProbe:
    # clearEvents.startupProbe.enabled Enable startupProbe for Clear Events container
    enabled: true
    httpGet:
      # clearEvents.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # clearEvents.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # clearEvents.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # clearEvents.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `clearEvents.readinessProbe.enabled=true`
  readinessProbe:
    # clearEvents.readinessProbe.enabled Enable readinessProbe for Clear Events container
    enabled: true
    # clearEvents.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # clearEvents.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # clearEvents.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # clearEvents.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # clearEvents.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # clearEvents.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `clearEvents.livenessProbe.enabled=true`
  livenessProbe:
    # clearEvents.livenessProbe.enabled Enable livenessProbe for Clear Events container
    enabled: true
    # clearEvents.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # clearEvents.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # clearEvents.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # clearEvents.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # clearEvents.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # clearEvents.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Clear Events container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # clearEvents.resources.requests The requested resources for the Clear Events container
  # clearEvents.resources.limits The resources limits for the Clear Events container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # clearEvents.mysqlUser Database user who will be used by the Clear Events service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Doceditor application parameters
# This block defines the parameters common to all the Pods of this application
#
doceditor:
  # doceditor.enabled Enables Doceditor installation
  enabled: true
  # doceditor.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # doceditor.replicaCount Number of Doceditor replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # doceditor.updateStrategy.type Doceditor update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `doceditor.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `doceditor.kind` is set to `Deployment`
    type: RollingUpdate
    # doceditor.updateStrategy.rollingUpdate Used only when `doceditor.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # doceditor.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Doceditor Pods unavailable during the update process
      maxUnavailable: 25%
      # doceditor.updateStrategy.rollingUpdate.maxSurge Maximum number of Doceditor Pods created over the desired number of Pods
      maxSurge: 25%
  # doceditor.podManagementPolicy The Doceditor Pods scaling operations policy
  # Used if `doceditor.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Doceditor Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # doceditor.podSecurityContext.enabled Enable security context for the Doceditor pods
    enabled: false
  # doceditor.customPodAntiAffinity Prohibiting the scheduling of Doceditor Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Doceditor Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Doceditor Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Doceditor Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Doceditor Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # doceditor.nodeSelector Node labels for Doceditor pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # doceditor.tolerations Tolerations for Doceditor pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Doceditor container image parameters
  image:
    # doceditor.image.repository Doceditor container image repository
    repository: onlyoffice/docspace-doceditor
    # doceditor.image.tag Doceditor container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # doceditor.image.pullPolicy Doceditor container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Doceditor Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # doceditor.containerSecurityContext.enabled Enable security context for containers in Doceditor pods
    enabled: false
  containerPorts:
    # doceditor.containerPorts.app Doceditor container port
    app: 5050
    # doceditor.containerPorts.doceditor Doceditor additional container port
    doceditor: 5013
  # Probe used for the Doceditor container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `doceditor.startupProbe.enabled=true`
  startupProbe:
    # doceditor.startupProbe.enabled Enable startupProbe for Doceditor container
    enabled: true
    httpGet:
      # doceditor.startupProbe.httpGet.path Checking the path for startupProbe
      path: /doceditor/health
      # doceditor.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5013
    # doceditor.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # doceditor.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `doceditor.readinessProbe.enabled=true`
  readinessProbe:
    # doceditor.readinessProbe.enabled Enable readinessProbe for Doceditor container
    enabled: true
    # doceditor.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # doceditor.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /doceditor/health
      # doceditor.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5013
    # doceditor.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # doceditor.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # doceditor.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `doceditor.livenessProbe.enabled=true`
  livenessProbe:
    # doceditor.livenessProbe.enabled Enable livenessProbe for Doceditor container
    enabled: true
    # doceditor.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # doceditor.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /doceditor/health
      # doceditor.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5013
    # doceditor.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # doceditor.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # doceditor.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Doceditor container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # doceditor.resources.requests The requested resources for the Doceditor container
  # doceditor.resources.limits The resources limits for the Doceditor container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # doceditor.mysqlUser Database user who will be used by the Doceditor service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Files Services application parameters
# This block defines the parameters common to all the Pods of this application
#
filesServices:
  # filesServices.enabled Enables Files Services installation
  enabled: true
  # filesServices.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # filesServices.replicaCount Number of Files Services replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # filesServices.updateStrategy.type Files Services update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `filesServices.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `filesServices.kind` is set to `Deployment`
    type: RollingUpdate
    # filesServices.updateStrategy.rollingUpdate Used only when `filesServices.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # filesServices.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Files Services Pods unavailable during the update process
      maxUnavailable: 25%
      # filesServices.updateStrategy.rollingUpdate.maxSurge Maximum number of Files Services Pods created over the desired number of Pods
      maxSurge: 25%
  # filesServices.podManagementPolicy The Files Services Pods scaling operations policy
  # Used if `filesServices.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Files Services Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # filesServices.podSecurityContext.enabled Enable security context for the Files Services pods
    enabled: false
  # filesServices.customPodAntiAffinity Prohibiting the scheduling of Files Services Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Files Services Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Files Services Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Files Services Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Files Services Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # filesServices.nodeSelector Node labels for Files Services pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # filesServices.tolerations Tolerations for Files Services pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Files Services container image parameters
  image:
    # filesServices.image.repository Files Services container image repository
    repository: onlyoffice/docspace-files-services
    # filesServices.image.tag Files Services container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # filesServices.image.pullPolicy Files Services container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Files Services Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # filesServices.containerSecurityContext.enabled Enable security context for containers in Files Services pods
    enabled: false
  # filesServices.containerPorts.app Files Services container port
  containerPorts:
    app: 5050
  # Probe used for the Files Services container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `filesServices.startupProbe.enabled=true`
  startupProbe:
    # filesServices.startupProbe.enabled Enable startupProbe for Files Services container
    enabled: true
    httpGet:
      # filesServices.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # filesServices.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # filesServices.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # filesServices.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `filesServices.readinessProbe.enabled=true`
  readinessProbe:
    # filesServices.readinessProbe.enabled Enable readinessProbe for Files Services container
    enabled: true
    # filesServices.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # filesServices.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # filesServices.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # filesServices.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 20
    # filesServices.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # filesServices.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `filesServices.livenessProbe.enabled=true`
  livenessProbe:
    # filesServices.livenessProbe.enabled Enable livenessProbe for Files Services container
    enabled: true
    # filesServices.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # filesServices.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # filesServices.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # filesServices.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 20
    # filesServices.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # filesServices.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Files Services container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # filesServices.resources.requests The requested resources for the Files Services container
  # filesServices.resources.limits The resources limits for the Files Services container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # filesServices.mysqlUser Database user who will be used by the Files Services service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Login application parameters
# This block defines the parameters common to all the Pods of this application
#
login:
  # login.enabled Enables Login installation
  enabled: true
  # login.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # login.replicaCount Number of Login replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # login.updateStrategy.type Login update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `login.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `login.kind` is set to `Deployment`
    type: RollingUpdate
    # login.updateStrategy.rollingUpdate Used only when `login.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # login.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Login Pods unavailable during the update process
      maxUnavailable: 25%
      # login.updateStrategy.rollingUpdate.maxSurge Maximum number of Login Pods created over the desired number of Pods
      maxSurge: 25%
  # login.podManagementPolicy The Login Pods scaling operations policy
  # Used if `login.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Login Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # login.podSecurityContext.enabled Enable security context for the Login pods
    enabled: false
  # login.customPodAntiAffinity Prohibiting the scheduling of Login Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Login Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Login Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Login Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Login Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # login.nodeSelector Node labels for Login pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # login.tolerations Tolerations for Login pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Login container image parameters
  image:
    # login.image.repository Login container image repository
    repository: onlyoffice/docspace-login
    # login.image.tag Login container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # login.image.pullPolicy Login container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Login Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # login.containerSecurityContext.enabled Enable security context for containers in Login pods
    enabled: false
  # login.containerPorts.login Login container port
  containerPorts:
    login: 5011
  # Probe used for the Login container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `login.startupProbe.enabled=true`
  startupProbe:
    # login.startupProbe.enabled Enable startupProbe for Login container
    enabled: true
    httpGet:
      # login.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # login.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5011
    # login.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # login.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `login.readinessProbe.enabled=true`
  readinessProbe:
    # login.readinessProbe.enabled Enable readinessProbe for Login container
    enabled: true
    # login.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # login.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # login.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5011
    # login.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # login.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # login.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `login.livenessProbe.enabled=true`
  livenessProbe:
    # login.livenessProbe.enabled Enable livenessProbe for Login container
    enabled: true
    # login.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # login.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # login.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5011
    # login.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # login.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # login.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Login container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # login.resources.requests The requested resources for the Login container
  # login.resources.limits The resources limits for the Login container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # login.mysqlUser Database user who will be used by the Login service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Notify application parameters
# This block defines the parameters common to all the Pods of this application
#
notify:
  # notify.enabled Enables Notify installation
  enabled: true
  # notify.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # notify.replicaCount Number of Notify replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # notify.updateStrategy.type Notify update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `notify.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `notify.kind` is set to `Deployment`
    type: RollingUpdate
    # notify.updateStrategy.rollingUpdate Used only when `notify.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # notify.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Notify Pods unavailable during the update process
      maxUnavailable: 25%
      # notify.updateStrategy.rollingUpdate.maxSurge Maximum number of Notify Pods created over the desired number of Pods
      maxSurge: 25%
  # notify.podManagementPolicy The Notify Pods scaling operations policy
  # Used if `notify.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Notify Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # notify.podSecurityContext.enabled Enable security context for the Notify pods
    enabled: false
  # notify.customPodAntiAffinity Prohibiting the scheduling of Notify Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Notify Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Notify Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Notify Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Notify Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # notify.nodeSelector Node labels for Notify pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # notify.tolerations Tolerations for Notify pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Notify container image parameters
  image:
    # notify.image.repository Notify container image repository
    repository: onlyoffice/docspace-notify
    # notify.image.tag Notify container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # notify.image.pullPolicy Notify container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Notify Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # notify.containerSecurityContext.enabled Enable security context for containers in Notify pods
    enabled: false
  # notify.containerPorts.app Notify container port
  containerPorts:
    app: 5050
  # Probe used for the Notify container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `notify.startupProbe.enabled=true`
  startupProbe:
    # notify.startupProbe.enabled Enable startupProbe for Notify container
    enabled: true
    httpGet:
      # notify.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # notify.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # notify.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # notify.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `notify.readinessProbe.enabled=true`
  readinessProbe:
    # notify.readinessProbe.enabled Enable readinessProbe for Notify container
    enabled: true
    # notify.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # notify.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # notify.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # notify.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # notify.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # notify.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `notify.livenessProbe.enabled=true`
  livenessProbe:
    # notify.livenessProbe.enabled Enable livenessProbe for Notify container
    enabled: true
    # notify.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # notify.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # notify.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # notify.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # notify.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # notify.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Notify container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # notify.resources.requests The requested resources for the Notify container
  # notify.resources.limits The resources limits for the Notify container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # notify.mysqlUser Database user who will be used by the Notify service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Socket application parameters
# This block defines the parameters common to all the Pods of this application
#
socket:
  # socket.enabled Enables Socket installation
  enabled: true
  # socket.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # socket.replicaCount Number of Socket replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # socket.updateStrategy.type Socket update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `socket.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `socket.kind` is set to `Deployment`
    type: RollingUpdate
    # socket.updateStrategy.rollingUpdate Used only when `socket.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # socket.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Socket Pods unavailable during the update process
      maxUnavailable: 25%
      # socket.updateStrategy.rollingUpdate.maxSurge Maximum number of Socket Pods created over the desired number of Pods
      maxSurge: 25%
  # socket.podManagementPolicy The Socket Pods scaling operations policy
  # Used if `socket.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Socket Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # socket.podSecurityContext.enabled Enable security context for the Socket pods
    enabled: false
  # socket.customPodAntiAffinity Prohibiting the scheduling of Socket Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Socket Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Socket Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Socket Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Socket Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # socket.nodeSelector Node labels for Socket pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # socket.tolerations Tolerations for Socket pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Socket container image parameters
  image:
    # socket.image.repository Socket container image repository
    repository: onlyoffice/docspace-socket
    # socket.image.tag Socket container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # socket.image.pullPolicy Socket container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Socket Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # socket.containerSecurityContext.enabled Enable security context for containers in Socket pods
    enabled: false
  containerPorts:
    # socket.containerPorts.app Socket container port
    app: 5050
    # socket.containerPorts.socket Socket additional container port
    socket: 9899
  # Probe used for the Socket container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `socket.startupProbe.enabled=true`
  startupProbe:
    # socket.startupProbe.enabled Enable startupProbe for Socket container
    enabled: true
    httpGet:
      # socket.startupProbe.httpGet.path Checking the path for startupProbe
      path: /
      # socket.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # socket.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # socket.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `socket.readinessProbe.enabled=true`
  readinessProbe:
    # socket.readinessProbe.enabled Enable readinessProbe for Socket container
    enabled: true
    # socket.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # socket.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /
      # socket.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # socket.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # socket.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # socket.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `socket.livenessProbe.enabled=true`
  livenessProbe:
    # socket.livenessProbe.enabled Enable livenessProbe for Socket container
    enabled: true
    # socket.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # socket.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /
      # socket.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # socket.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # socket.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # socket.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Socket container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # socket.resources.requests The requested resources for the Socket container
  # socket.resources.limits The resources limits for the Socket container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # socket.mysqlUser Database user who will be used by the Socket service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace ssoauth application parameters
# This block defines the parameters common to all the Pods of this application
#
ssoauth:
  # ssoauth.enabled Enables ssoauth installation
  enabled: true
  # ssoauth.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # ssoauth.replicaCount Number of ssoauth replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # ssoauth.updateStrategy.type ssoauth update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `ssoauth.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `ssoauth.kind` is set to `Deployment`
    type: RollingUpdate
    # ssoauth.updateStrategy.rollingUpdate Used only when `ssoauth.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # ssoauth.updateStrategy.rollingUpdate.maxUnavailable Maximum number of ssoauth Pods unavailable during the update process
      maxUnavailable: 25%
      # ssoauth.updateStrategy.rollingUpdate.maxSurge Maximum number of ssoauth Pods created over the desired number of Pods
      maxSurge: 25%
  # ssoauth.podManagementPolicy The ssoauth Pods scaling operations policy
  # Used if `ssoauth.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the ssoauth Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # ssoauth.podSecurityContext.enabled Enable security context for the ssoauth pods
    enabled: false
  # ssoauth.customPodAntiAffinity Prohibiting the scheduling of ssoauth Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for ssoauth Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes ssoauth Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for ssoauth Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes ssoauth Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # ssoauth.nodeSelector Node labels for ssoauth pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # ssoauth.tolerations Tolerations for ssoauth pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # ssoauth container image parameters
  image:
    # ssoauth.image.repository ssoauth container image repository
    repository: onlyoffice/docspace-ssoauth
    # ssoauth.image.tag ssoauth container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # ssoauth.image.pullPolicy ssoauth container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in ssoauth Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # ssoauth.containerSecurityContext.enabled Enable security context for containers in ssoauth pods
    enabled: false
  containerPorts:
    # ssoauth.containerPorts.app ssoauth container port
    app: 5050
    # ssoauth.containerPorts.sso ssoauth additional container port
    sso: 9834
  # Probe used for the ssoauth container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `ssoauth.startupProbe.enabled=true`
  startupProbe:
    # ssoauth.startupProbe.enabled Enable startupProbe for ssoauth container
    enabled: true
    tcpSocket:
      # ssoauth.startupProbe.tcpSocket.port Checking the port for startupProbe
      port: 5050
    # ssoauth.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # ssoauth.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `ssoauth.readinessProbe.enabled=true`
  readinessProbe:
    # ssoauth.readinessProbe.enabled Enable readinessProbe for ssoauth container
    enabled: true
    # ssoauth.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    tcpSocket:
      # ssoauth.readinessProbe.tcpSocket.port Checking the port for readinessProbe
      port: 5050
    # ssoauth.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # ssoauth.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # ssoauth.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `ssoauth.livenessProbe.enabled=true`
  livenessProbe:
    # ssoauth.livenessProbe.enabled Enable livenessProbe for ssoauth container
    enabled: true
    # ssoauth.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    tcpSocket:
      # ssoauth.livenessProbe.tcpSocket.port Checking the port for livenessProbe
      port: 5050
    # ssoauth.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # ssoauth.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # ssoauth.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # ssoauth container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # ssoauth.resources.requests The requested resources for the ssoauth container
  # ssoauth.resources.limits The resources limits for the ssoauth container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # ssoauth.mysqlUser Database user who will be used by the ssoauth service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Studio application parameters
# This block defines the parameters common to all the Pods of this application
#
studio:
  # studio.enabled Enables Studio installation
  enabled: true
  # studio.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # studio.replicaCount Number of Studio replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # studio.updateStrategy.type Studio update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `studio.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `studio.kind` is set to `Deployment`
    type: RollingUpdate
    # studio.updateStrategy.rollingUpdate Used only when `studio.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # studio.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Studio Pods unavailable during the update process
      maxUnavailable: 25%
      # studio.updateStrategy.rollingUpdate.maxSurge Maximum number of Studio Pods created over the desired number of Pods
      maxSurge: 25%
  # studio.podManagementPolicy The Studio Pods scaling operations policy
  # Used if `studio.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Studio Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # studio.podSecurityContext.enabled Enable security context for the Studio pods
    enabled: false
  # studio.customPodAntiAffinity Prohibiting the scheduling of Studio Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Studio Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Studio Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Studio Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Studio Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # studio.nodeSelector Node labels for Studio pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # studio.tolerations Tolerations for Studio pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Studio container image parameters
  image:
    # studio.image.repository Studio container image repository
    repository: onlyoffice/docspace-studio
    # studio.image.tag Studio container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # studio.image.pullPolicy Studio container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Studio Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # studio.containerSecurityContext.enabled Enable security context for containers in Studio pods
    enabled: false
  # studio.containerPorts.app Studio container port
  containerPorts:
    app: 5050
  # Probe used for the Studio container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `studio.startupProbe.enabled=true`
  startupProbe:
    # studio.startupProbe.enabled Enable startupProbe for Studio container
    enabled: true
    httpGet:
      # studio.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # studio.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # studio.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # studio.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `studio.readinessProbe.enabled=true`
  readinessProbe:
    # studio.readinessProbe.enabled Enable readinessProbe for Studio container
    enabled: true
    # studio.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # studio.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # studio.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # studio.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # studio.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # studio.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `studio.livenessProbe.enabled=true`
  livenessProbe:
    # studio.livenessProbe.enabled Enable livenessProbe for Studio container
    enabled: true
    # studio.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # studio.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # studio.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # studio.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # studio.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # studio.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Studio container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # studio.resources.requests The requested resources for the Studio container
  # studio.resources.limits The resources limits for the Studio container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # studio.mysqlUser Database user who will be used by the Studio service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Studio Notify application parameters
# This block defines the parameters common to all the Pods of this application
#
studioNotify:
  # studioNotify.enabled Enables Studio Notify installation
  enabled: true
  # studioNotify.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # studioNotify.replicaCount Number of Studio Notify replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # studioNotify.updateStrategy.type Studio Notify update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `studioNotify.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `studioNotify.kind` is set to `Deployment`
    type: RollingUpdate
    # studioNotify.updateStrategy.rollingUpdate Used only when `studioNotify.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # studioNotify.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Studio Notify Pods unavailable during the update process
      maxUnavailable: 25%
      # studioNotify.updateStrategy.rollingUpdate.maxSurge Maximum number of Studio Notify Pods created over the desired number of Pods
      maxSurge: 25%
  # studioNotify.podManagementPolicy The Studio Notify Pods scaling operations policy
  # Used if `studioNotify.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # Configure a Security Context for the Studio Notify Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # studioNotify.podSecurityContext.enabled Enable security context for the Studio Notify pods
    enabled: false
  # studioNotify.customPodAntiAffinity Prohibiting the scheduling of Studio Notify Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Studio Notify Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Studio Notify Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Studio Notify Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Studio Notify Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # studioNotify.nodeSelector Node labels for Studio Notify pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # studioNotify.tolerations Tolerations for Studio Notify pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Studio Notify container image parameters
  image:
    # studioNotify.image.repository Studio Notify container image repository
    repository: onlyoffice/docspace-studio-notify
    # studioNotify.image.tag Studio Notify container image tag
    # If set to, it takes priority over the `images.tag`
    tag: ""
    # studioNotify.image.pullPolicy Studio Notify container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Studio Notify Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # studioNotify.containerSecurityContext.enabled Enable security context for containers in Studio Notify pods
    enabled: false
  # studioNotify.containerPorts.app Studio Notify container port
  containerPorts:
    app: 5050
  # Probe used for the Studio Notify container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `studioNotify.startupProbe.enabled=true`
  startupProbe:
    # studioNotify.startupProbe.enabled Enable Startup Probe for studioNotify container
    enabled: true
    httpGet:
      # studioNotify.startupProbe.httpGet.path Checking the path for startupProbe
      path: /health
      # studioNotify.startupProbe.httpGet.port Checking the port for startupProbe
      port: 5050
    # studioNotify.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # studioNotify.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `studioNotify.readinessProbe.enabled=true`
  readinessProbe:
    # studioNotify.readinessProbe.enabled Enable readinessProbe for Studio Notify container
    enabled: true
    # studioNotify.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # studioNotify.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /health
      # studioNotify.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 5050
    # studioNotify.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 10
    # studioNotify.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # studioNotify.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `studioNotify.livenessProbe.enabled=true`
  livenessProbe:
    # studioNotify.livenessProbe.enabled Enable livenessProbe for Studio Notify container
    enabled: true
    # studioNotify.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # studioNotify.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /health
      # studioNotify.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 5050
    # studioNotify.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 10
    # studioNotify.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # studioNotify.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Studio Notify container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # studioNotify.resources.requests The requested resources for the Studio Notify container
  # studioNotify.resources.limits The resources limits for the Studio Notify container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # studioNotify.mysqlUser Database user who will be used by the Studio Notify service to connect to the database
  # If not set, `connections.mysqlUser` will be used
  # If set to, it takes priority over the `connections.mysqlUser`
  mysqlUser: ""

# DocSpace Proxy Frontend application parameters
# This block defines the parameters common to all the Pods of this application
#
proxyFrontend:
  # proxyFrontend.enabled Enables Proxy Frontend installation
  enabled: false
  # proxyFrontend.kind The controller used for deploy
  # Possible values are `Deployment` (default) or `StatefulSet`
  kind: Deployment
  # proxyFrontend.replicaCount Number of Proxy Frontend replicas to deploy
  replicaCount: 2
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # proxyFrontend.updateStrategy.type Proxy Frontend update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete` if `proxyFrontend.kind` is set to `StatefulSet` and `RollingUpdate` or `Recreate` if `proxyFrontend.kind` is set to `Deployment`
    type: RollingUpdate
    # proxyFrontend.updateStrategy.rollingUpdate Used only when `proxyFrontend.updateStrategy.type=RollingUpdate`
    rollingUpdate:
      # proxyFrontend.updateStrategy.rollingUpdate.maxUnavailable Maximum number of Proxy Frontend Pods unavailable during the update process
      maxUnavailable: 25%
      # proxyFrontend.updateStrategy.rollingUpdate.maxSurge Maximum number of Proxy Frontend Pods created over the desired number of Pods
      maxSurge: 25%
  # proxyFrontend.podManagementPolicy The Proxy Frontend Pods scaling operations policy
  # Used if `proxyFrontend.kind` is set to `StatefulSet`
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady
  # proxyFrontend.podAnnotations Map of annotations to add to the Proxy Frontend pods
  podAnnotations: {}
  # Configure a Security Context for the Proxy Frontend Pods
  # If set to, it takes priority over the `podSecurityContext`
  podSecurityContext:
    # proxyFrontend.podSecurityContext.enabled Enable security context for the Proxy Frontend pods
    enabled: false
  # proxyFrontend.customPodAntiAffinity Prohibiting the scheduling of Proxy Frontend Pods relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Proxy Frontend Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Proxy Frontend Pods can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Proxy Frontend Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Proxy Frontend Pods can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # proxyFrontend.nodeSelector Node labels for Proxy Frontend pods assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # proxyFrontend.tolerations Tolerations for Proxy Frontend pods assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Proxy Frontend initContainers parameters
  # proxyFrontend.initContainers Containers that run before Proxy Frontend container in a Pod
  # ref:https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  # Example:
  # initContainers:
  #   - name: custom-init-container
  #     image: busybox:latest
  #     command: ['sh', '-c', 'sleep 180']
  initContainers: []
  # Proxy Frontend container image parameters
  image:
    # proxyFrontend.image.repository Proxy Frontend container image repository
    repository: nginx
    # proxyFrontend.image.tag Proxy Frontend container image tag
    tag: latest
    # proxyFrontend.image.pullPolicy Proxy Frontend container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Proxy Frontend Pods
  # If set to, it takes priority over the `containerSecurityContext`
  containerSecurityContext:
    # proxyFrontend.containerSecurityContext.enabled Enable security context for containers in Proxy Frontend pods
    enabled: false
  containerPorts:
    # proxyFrontend.containerPorts.http Proxy Frontend HTTP container port
    http: 80
    # proxyFrontend.containerPorts.https Proxy Frontend HTTPS container port
    https: 443
  # Probe used for the proxyFrontend container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `proxyFrontend.startupProbe.enabled=true`
  startupProbe:
    # proxyFrontend.startupProbe.enabled Enable startupProbe for Proxy Frontend container
    enabled: true
    httpGet:
      # proxyFrontend.startupProbe.httpGet.path Checking the path for startupProbe
      path: /
      # proxyFrontend.startupProbe.httpGet.port Checking the port for startupProbe
      port: 80
    # proxyFrontend.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # proxyFrontend.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `proxyFrontend.readinessProbe.enabled=true`
  readinessProbe:
    # proxyFrontend.readinessProbe.enabled Enable readinessProbe for Proxy Frontend container
    enabled: true
    # proxyFrontend.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # proxyFrontend.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /
      # proxyFrontend.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 80
    # proxyFrontend.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 20
    # proxyFrontend.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # proxyFrontend.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `proxyFrontend.livenessProbe.enabled=true`
  livenessProbe:
    # proxyFrontend.livenessProbe.enabled Enable livenessProbe for Proxy Frontend container
    enabled: true
    # proxyFrontend.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # proxyFrontend.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /
      # proxyFrontend.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 80
    # proxyFrontend.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 20
    # proxyFrontend.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # proxyFrontend.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Proxy Frontend container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # proxyFrontend.resources.requests The requested resources for the Proxy Frontend container
  # proxyFrontend.resources.limits The resources limits for the Proxy Frontend container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  # Additional configuration files for Proxy Frontend
  extraConf:
    confd:
      # proxyFrontend.extraConf.confd.configMap The name of the ConfigMap containing custom configuration files
      # These files will be map in the `/etc/nginx/conf.d/` directory of the container
      configMap: default-conf
      # proxyFrontend.extraConf.confd.fileName The names of the configuration files containing custom configuration files
      # Must be the same as the `key` names in `proxyFrontend.extraConf.confd.configMap`
      # May contain multiple values
      fileName:
        - default.conf
    customConfd:
      # proxyFrontend.extraConf.customConfd.configMap The name of the ConfigMap containing additional custom configuration files
      # These files will be map in the `/etc/nginx/conf.d/` directory of the container
      configMap: ""
      # proxyFrontend.extraConf.customConfd.fileName The names of the configuration files containing additional custom configuration files
      # Must be the same as the `key` names in `proxyFrontend.extraConf.customConfd.configMap`
      # May contain multiple values
      fileName:
        - example.conf
  # proxyFrontend.hostname The hostname (domainname) by which the DocSpace will be available
  hostname: ""
  # Proxy Frontend TLS parameters
  tls:
    # proxyFrontend.tls.secretName The name of the TLS secret containing the certificate and its associated key
    # If not set, the parameters below are ignored
    secretName: tls
    # proxyFrontend.tls.mountPath The path where the certificate and key will be mounted
    mountPath: /etc/nginx/ssl
    # proxyFrontend.tls.crtName Name of the key containing the certificate
    crtName: cert.crt
    # proxyFrontend.tls.keyName Name of the key containing the key
    keyName: cert.key
  # Proxy Frontend service parameters
  service:
    # proxyFrontend.service.existing The name of an existing service for Proxy Frontend. If not set, a service named `proxy-frontend` will be created
    # ref: https://github.com/ONLYOFFICE/Kubernetes-DocSpace/blob/master/templates/services/proxy-frontend.yaml
    existing: ""
    # proxyFrontend.service.annotations Map of annotations to add to the Proxy Frontend service
    annotations: {}
    # proxyFrontend.service.type Proxy Frontend service type
    type: LoadBalancer

# DocSpace Document Server StatefulSet parameters
#
docs:
  # docs.enabled Enables local installation of Document Server in k8s cluster
  enabled: true
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # docs.updateStrategy.type Document Server update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete`
    type: RollingUpdate
  # docs.podAnnotations Map of annotations to add to the Document Server pod
  podAnnotations: {}
  # Configure a Security Context for the Document Server Pod
  podSecurityContext:
    # docs.podSecurityContext.enabled Enable security context for the Document Server Pod
    enabled: false
    # docs.podSecurityContext.fsGroup Defines the Group ID to which the owner and permissions for all files in volumes are changed when mounted in the Document Server Pod
    fsGroup: 101
  # docs.customPodAntiAffinity Prohibiting the scheduling of Document Server Pod relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Document Server Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Document Server Pod can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Document Server Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Document Server Pod can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # docs.nodeSelector Node labels for Document Server pod assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # docs.tolerations Tolerations for Document Server pod assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  # Document Server initContainers parameters
  # docs.initContainers Containers that run before Document Server container in a Pod
  # ref:https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  # Example:
  # initContainers:
  #   - name: custom-init-container
  #     image: busybox:latest
  #     command: ['sh', '-c', 'sleep 180']
  initContainers: []
  # docs container image parameters
  image:
    # docs.image.repository Document Server container image repository
    repository: onlyoffice/documentserver
    # docs.image.tag Document Server container image tag
    tag: latest
    # docs.image.pullPolicy Document Server container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for containers in Document Server Pod
  containerSecurityContext:
    # docs.containerSecurityContext.enabled Enable security context for container in Document Server pod
    enabled: false
    # docs.containerSecurityContext.runAsUser User ID for the Document Server container
    runAsUser: 101
    # docs.containerSecurityContext.runAsGroup Group ID for the Document Server container
    runAsGroup: 101
    # docs.containerSecurityContext.runAsNonRoot Require that the container will run with a user with UID other than 0
    runAsNonRoot: true
    # docs.containerSecurityContext.allowPrivilegeEscalation Controls whether a process can gain more privileges than its parent process
    allowPrivilegeEscalation: false
    # docs.containerSecurityContext.seLinuxOptions Defines SELinux labels for the Document Server container
    seLinuxOptions: {}
    # docs.containerSecurityContext.seccompProfile Defines the Seccomp profile for the Document Server container
    seccompProfile:
      type: RuntimeDefault
    # docs.containerSecurityContext.capabilities Defines the privileges granted to the process
    capabilities:
      drop: ["ALL"]
  containerPorts:
    # docs.containerPorts.http Document Server HTTP container port
    http: 80
    # docs.containerPorts.https Document Server HTTPS container port
    https: 443
    # docs.containerPorts.docservice Document Server docservice container port
    docservice: 8000
  # Probe used for the Document Server container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `docs.startupProbe.enabled=true`
  startupProbe:
    # docs.startupProbe.enabled Enable startupProbe for Document Server container
    enabled: true
    httpGet:
      # docs.startupProbe.httpGet.path Checking the path for startupProbe
      path: /index.html
      # docs.startupProbe.httpGet.port Checking the port for startupProbe
      port: 80
    # docs.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # docs.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 20
  # The parameters below for readiness probes are used only when `docs.readinessProbe.enabled=true`
  readinessProbe:
    # docs.readinessProbe.enabled Enable readinessProbe for Document Server container
    enabled: true
    # docs.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    httpGet:
      # docs.readinessProbe.httpGet.path Checking the path for readinessProbe
      path: /index.html
      # docs.readinessProbe.httpGet.port Checking the port for readinessProbe
      port: 80
    # docs.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 20
    # docs.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # docs.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `docs.livenessProbe.enabled=true`
  livenessProbe:
    # docs.livenessProbe.enabled Enable livenessProbe for Document Server container
    enabled: true
    # docs.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    httpGet:
      # docs.livenessProbe.httpGet.path Checking the path for livenessProbe
      path: /index.html
      # docs.livenessProbe.httpGet.port Checking the port for livenessProbe
      port: 80
    # docs.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 20
    # docs.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # docs.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Document Server container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # docs.resources.requests The requested resources for the Document Server container
  # docs.resources.limits The resources limits for the Document Server container
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "4Gi"
      cpu: "4000m"

# DocSpace ingress parameters
# NGINX Ingress Controller must be installed
# ref: https://github.com/ONLYOFFICE/Kubernetes-DocSpace#121-installing-the-kubernetes-nginx-ingress-controller
#
ingress:
  # ingress.enabled Enable the creation of an ingress for the DocSpace
  enabled: false
  # ingress.annotations Map of annotations to add to the Ingress
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 100m
  # ingress.ingressClassName Used to reference the IngressClass that should be used to implement this Ingress
  # ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#the-ingress-resource/
  ingressClassName: nginx
  tls:
    # ingress.tls.enabled Enable TLS for the DocSpace
    enabled: false
    # ingress.tls.secretName Secret name for TLS to mount into the Ingress
    # Used only when `ingress.tls.enabled=true`
    secretName: tls
  # ingress.host Ingress hostname for the DocSpace
  host: ""

# DocSpace jobs parameters
#
# Job by install has a pre-install hook and executes before any resources are created in Kubernetes
# ref: https://helm.sh/docs/topics/charts_hooks/#the-available-hooks
# He creates tables, initializes the database in the `connections.mysqlDatabase` database and initializes the storage for DocSpace
install:
  job:
    # install.job.enabled Enable the execution of job pre-install before installing DocSpace
    enabled: true
    # Configure a Security Context for the Install Job Pod
    # If set to, it takes priority over the `podSecurityContext`
    podSecurityContext:
      # install.job.podSecurityContext.enabled Enable security context for the Install Job pod
      enabled: false
    # install.job.customPodAntiAffinity Prohibiting the scheduling of Install Job Pod relative to other Pods containing the specified labels on the same node
    customPodAntiAffinity: {}
    # Pod affinity rules for Install Job Pod scheduling by nodes relative to other Pods
    # Pod affinity allow you to constrain which nodes Install Job Pod can be scheduled on based on the labels of Pods already running on that node
    # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    # Example:
    # podAffinity:
    #   preferredDuringSchedulingIgnoredDuringExecution:
    #   - weight: 100
    #     podAffinityTerm:
    #       labelSelector:
    #         matchExpressions:
    #         - key: app
    #           operator: NotIn
    #           values:
    #           - database
    #       topologyKey: kubernetes.io/hostname
    podAffinity: {}
    # Node affinity rules for Install Job Pod scheduling by nodes
    # Node affinity allow you to constrain which nodes Install Job Pod can be scheduled on based on node labels
    # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
    # Example:
    # nodeAffinity:
    #   preferredDuringSchedulingIgnoredDuringExecution:
    #   - weight: 100
    #     preference:
    #       matchExpressions:
    #       - key: kubernetes.io/name
    #         operator: In
    #         values:
    #         - name1
    #         - name2
    nodeAffinity: {}
    # install.job.nodeSelector Node labels for Install Job pod assignment
    # If set to, it takes priority over the `nodeSelector`
    nodeSelector: {}
    # install.job.tolerations Tolerations for Install Job pod assignment
    # If set to, it takes priority over the `tolerations`
    tolerations: []
    # Configure a Security Context for containers in Install Job Pod
    # If set to, it takes priority over the `containerSecurityContext`
    containerSecurityContext:
      # install.job.containerSecurityContext.enabled Enable security context for containers in Install Job pod
      enabled: false
    initContainers:
      migrationRunner:
        # install.job.initContainers.migrationRunner.enabled Enable database initialization
        enabled: true
        image:
          # install.job.initContainers.migrationRunner.image.repository Job by pre-install Migration Runner container image repository
          repository: onlyoffice/docspace-migration-runner
          # install.job.initContainers.migrationRunner.image.tag Job by pre-install Migration Runner container image tag
          # If set to, it takes priority over the `images.tag`
          tag: ""
          # install.job.initContainers.migrationRunner.image.pullPolicy Job by pre-install Migration Runner container image pull policy
          pullPolicy: IfNotPresent
        # Job pre-install Migration Runner container resource requests and limits
        # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
        # install.job.initContainers.migrationRunner.resources.requests The requested resources for the Job pre-install Migration Runner container
        # install.job.initContainers.migrationRunner.resources.limits The resources limits for the Job pre-install Migration Runner container
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
# Job by upgrade has a pre-upgrade hook and executes on an upgrade request before all of the release's resources have been upgraded
# ref: https://helm.sh/docs/topics/charts_hooks/#the-available-hooks
# He updates the `connections.mysqlDatabase` database and reinitializes the storage for DocSpace
upgrade:
  job:
    # upgrade.job.enabled Enable the execution of job pre-upgrade before upgrading DocSpace
    enabled: true
    # Configure a Security Context for the Upgrade Job Pod
    # If set to, it takes priority over the `podSecurityContext`
    podSecurityContext:
      # upgrade.job.podSecurityContext.enabled Enable security context for the Upgrade Job pod
      enabled: false
    # upgrade.job.customPodAntiAffinity Prohibiting the scheduling of Upgrade Job Pod relative to other Pods containing the specified labels on the same node
    customPodAntiAffinity: {}
    # Pod affinity rules for Upgrade Job Pod scheduling by nodes relative to other Pods
    # Pod affinity allow you to constrain which nodes Upgrade Job Pod can be scheduled on based on the labels of Pods already running on that node
    # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    # Example:
    # podAffinity:
    #   preferredDuringSchedulingIgnoredDuringExecution:
    #   - weight: 100
    #     podAffinityTerm:
    #       labelSelector:
    #         matchExpressions:
    #         - key: app
    #           operator: NotIn
    #           values:
    #           - database
    #       topologyKey: kubernetes.io/hostname
    podAffinity: {}
    # Node affinity rules for Upgrade Job Pod scheduling by nodes
    # Node affinity allow you to constrain which nodes Upgrade Job Pod can be scheduled on based on node labels
    # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
    # Example:
    # nodeAffinity:
    #   preferredDuringSchedulingIgnoredDuringExecution:
    #   - weight: 100
    #     preference:
    #       matchExpressions:
    #       - key: kubernetes.io/name
    #         operator: In
    #         values:
    #         - name1
    #         - name2
    nodeAffinity: {}
    # upgrade.job.nodeSelector Node labels for Upgrade Job pod assignment
    # If set to, it takes priority over the `nodeSelector`
    nodeSelector: {}
    # upgrade.job.tolerations Tolerations for Upgrade Job pod assignment
    # If set to, it takes priority over the `tolerations`
    tolerations: []
    # Configure a Security Context for containers in Upgrade Job Pod
    # If set to, it takes priority over the `containerSecurityContext`
    containerSecurityContext:
      # upgrade.job.containerSecurityContext.enabled Enable security context for containers in Upgrade Job pod
      enabled: false
    initContainers:
      migrationRunner:
        # upgrade.job.initContainers.migrationRunner.enabled Enable database update
        enabled: true
        image:
          # upgrade.job.initContainers.migrationRunner.image.repository Job by pre-upgrade Migration Runner container image repository
          repository: onlyoffice/docspace-migration-runner
          # upgrade.job.initContainers.migrationRunner.image.tag Job by pre-upgrade Migration Runner container image tag
          # If set to, it takes priority over the `images.tag`
          tag: ""
          # upgrade.job.initContainers.migrationRunner.image.pullPolicy Job by pre-upgrade Migration Runner container image pull policy
          pullPolicy: IfNotPresent
        # Job pre-upgrade Migration Runner container resource requests and limits
        # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
        # upgrade.job.initContainers.migrationRunner.resources.requests The requested resources for the Job pre-upgrade Migration Runner container
        # upgrade.job.initContainers.migrationRunner.resources.limits The resources limits for the Job pre-upgrade Migration Runner container
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "1000m"

# DocSpace Opensearch StatefulSet parameters
#
opensearch:
  # opensearch.enabled Enables Opensearch installation
  enabled: true
  # Update strategy used to replace old Pods by new ones
  updateStrategy:
    # opensearch.updateStrategy.type Opensearch update strategy type
    # Allowed values: `RollingUpdate` or `OnDelete`
    type: RollingUpdate
  # opensearch.podAnnotations Map of annotations to add to the Opensearch pod
  podAnnotations: {}
  # Configure a Security Context for the Opensearch Pod
  podSecurityContext:
    # opensearch.podSecurityContext.enabled Enable security context for the Opensearch Pod
    enabled: false
    # opensearch.podSecurityContext.fsGroup Defines the Group ID to which the owner and permissions for all files in volumes are changed when mounted in the Opensearch Pod
    fsGroup: 1000
  # opensearch.customPodAntiAffinity Prohibiting the scheduling of Opensearch Pod relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Opensearch Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Opensearch Pod can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  # Example:
  # podAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     podAffinityTerm:
  #       labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: NotIn
  #           values:
  #           - database
  #       topologyKey: kubernetes.io/hostname
  podAffinity: {}
  # Node affinity rules for Opensearch Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Opensearch Pod can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  # Example:
  # nodeAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #   - weight: 100
  #     preference:
  #       matchExpressions:
  #       - key: kubernetes.io/name
  #         operator: In
  #         values:
  #         - name1
  #         - name2
  nodeAffinity: {}
  # opensearch.nodeSelector Node labels for Opensearch pod assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # opensearch.tolerations Tolerations for Opensearch pod assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  initContainers:
    # Configure a Security Context for Opensearch change-volume-owner initContainer container in Pod
    securityContext:
      # opensearch.initContainers.securityContext.enabled Enable security context for Opensearch change-volume-owner initContainer container in pod
      enabled: false
      # opensearch.initContainers.securityContext.runAsUser User ID for the Opensearch change-volume-owner initContainer container
      runAsUser: 0
      # opensearch.initContainers.securityContext.allowPrivilegeEscalation Controls whether a process can gain more privileges than its parent process
      allowPrivilegeEscalation: false
      # opensearch.initContainers.securityContext.seLinuxOptions Defines SELinux labels for the Opensearch change-volume-owner initContainer container
      seLinuxOptions: {}
      # opensearch.initContainers.securityContext.seccompProfile Defines the Seccomp profile for the Opensearch change-volume-owner initContainer container
      seccompProfile:
        type: RuntimeDefault
      # opensearch.initContainers.securityContext.capabilities Defines the privileges granted to the process
      capabilities:
        drop: ["ALL"]
    # Opensearch change-volume-owner initContainer resource requests and limits
    # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    # opensearch.initContainers.resources.requests The requested resources for the Opensearch change-volume-owner initContainer
    # opensearch.initContainers.resources.limits The resources limits for the Opensearch change-volume-owner initContainer
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "1000m"
    # opensearch.initContainers.custom Custom Opensearch initContainers parameters
    # Additional containers that run before Opensearch container in a Pod
    # Example:
    # custom:
    #   - name: additional-init-container
    #     image: busybox:latest
    #     command: ['sh', '-c', 'sleep 180']
    custom: []
  # Opensearch container image parameters
  image:
    # opensearch.image.repository Opensearch container image repository
    repository: onlyoffice/opensearch
    # opensearch.image.tag Opensearch container image tag
    tag: 2.11.1
    # opensearch.image.pullPolicy Opensearch container image pull policy
    pullPolicy: IfNotPresent
  # Configure a Security Context for Opensearch container in Pod
  containerSecurityContext:
    # opensearch.containerSecurityContext.enabled Enable security context for Opensearch container in pod
    enabled: false
    # opensearch.containerSecurityContext.runAsUser User ID for the Opensearch container
    runAsUser: 1000
    # opensearch.containerSecurityContext.runAsGroup Group ID for the Opensearch container
    runAsGroup: 1000
    # opensearch.containerSecurityContext.runAsNonRoot Require that the container will run with a user with UID other than 0
    runAsNonRoot: true
    # opensearch.containerSecurityContext.allowPrivilegeEscalation Controls whether a process can gain more privileges than its parent process
    allowPrivilegeEscalation: false
    # opensearch.containerSecurityContext.seLinuxOptions Defines SELinux labels for the Opensearch container
    seLinuxOptions: {}
    # opensearch.containerSecurityContext.seccompProfile Defines the Seccomp profile for the Opensearch container
    seccompProfile:
      type: RuntimeDefault
    # opensearch.containerSecurityContext.capabilities Defines the privileges granted to the process
    capabilities:
      drop: ["ALL"]
  # Probe used for the Opensearch container: startup, readiness and liveness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # The parameters below for startup probes are used only when `opensearch.startupProbe.enabled=true`
  startupProbe:
    # opensearch.startupProbe.enabled Enable startupProbe for Opensearch container
    enabled: true
    tcpSocket:
      # opensearch.startupProbe.tcpSocket.port Checking the port for startupProbe
      port: 9200
    # opensearch.startupProbe.failureThreshold Failure threshold for startupProbe
    failureThreshold: 30
    # opensearch.startupProbe.periodSeconds Period seconds for startupProbe
    periodSeconds: 10
  # The parameters below for readiness probes are used only when `opensearch.readinessProbe.enabled=true`
  readinessProbe:
    # opensearch.readinessProbe.enabled Enable readinessProbe for Opensearch container
    enabled: true
    # opensearch.readinessProbe.failureThreshold Failure threshold for readinessProbe
    failureThreshold: 2
    tcpSocket:
      # opensearch.readinessProbe.tcpSocket.port Checking the port for readinessProbe
      port: 9200
    # opensearch.readinessProbe.periodSeconds Period seconds for readinessProbe
    periodSeconds: 20
    # opensearch.readinessProbe.successThreshold Success threshold for readinessProbe
    successThreshold: 1
    # opensearch.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    timeoutSeconds: 5
  # The parameters below for liveness probes are used only when `opensearch.livenessProbe.enabled=true`
  livenessProbe:
    # opensearch.livenessProbe.enabled Enable livenessProbe for Opensearch container
    enabled: true
    # opensearch.livenessProbe.failureThreshold Failure threshold for livenessProbe
    failureThreshold: 3
    tcpSocket:
      # opensearch.livenessProbe.tcpSocket.port Checking the port for livenessProbe
      port: 9200
    # opensearch.livenessProbe.periodSeconds Period seconds for livenessProbe
    periodSeconds: 20
    # opensearch.livenessProbe.successThreshold Success threshold for livenessProbe
    successThreshold: 1
    # opensearch.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    timeoutSeconds: 5
  # Opensearch container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # opensearch.resources.requests The requested resources for the opensearch container
  # opensearch.resources.limits The resources limits for the opensearch container
  resources:
    requests:
      memory: "1Gi"
      cpu: "1000m"
    limits:
      memory: "4Gi"
      cpu: "4000m"
  env:
    # opensearch.env.discoveryType determines the cluster discovery type. Set to "single-node" for a single-node cluster
    discoveryType: "single-node"
    # opensearch.env.disableSecurityPlugin disables the security plugin
    disableSecurityPlugin: true
    # opensearch.env.disableInstallDemoConfig disables the installation of demo configuration
    disableInstallDemoConfig: true
    # opensearch.env.bootstrapMemoryLock determines whether JVM should lock memory
    bootstrapMemoryLock: true
    # opensearch.env.ESJAVAOPTS defines JVM options
    ESJAVAOPTS: "-Xms2g -Xmx2g -Dlog4j2.formatMsgNoLookups=true"
    # opensearch.env.indicesFieldDataCacheSize sets the size of the index field data cache
    indicesFieldDataCacheSize: "30%"
    # opensearch.env.indicesMemoryIndexBufferSize sets the size of the in-memory index buffer
    indicesMemoryIndexBufferSize: "30%"
  persistence:
    # opensearch.persistence.storageClass PVC Storage Class for Opensearch volume
    storageClass: "nfs"
    # opensearch.persistence.accessModes Opensearch Persistent Volume access modes
    accessModes:
      - ReadWriteOnce
    # opensearch.persistence.size PVC Storage Request for Opensearch volume
    size: 30Gi

# DocSpace tests parameters
#
tests:
  # tests.enabled Enable the resources creation necessary for DocSpace launch testing and connected dependencies availability testing
  # These resources will be used when running the `helm test` command
  enabled: true
  # Configure a Security Context for the Test Pod
  podSecurityContext:
    # tests.podSecurityContext.enabled Enable security context for the Test pod
    enabled: false
    # tests.podSecurityContext.fsGroup Defines the Group ID to which the owner and permissions for all files in volumes are changed when mounted in the Test Pod
    fsGroup: 101
  # tests.customPodAntiAffinity Prohibiting the scheduling of Test Pod relative to other Pods containing the specified labels on the same node
  customPodAntiAffinity: {}
  # Pod affinity rules for Test Pod scheduling by nodes relative to other Pods
  # Pod affinity allow you to constrain which nodes Test Pod can be scheduled on based on the labels of Pods already running on that node
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  podAffinity: {}
  # Node affinity rules for Test Pod scheduling by nodes
  # Node affinity allow you to constrain which nodes Test Pod can be scheduled on based on node labels
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  nodeAffinity: {}
  # tests.nodeSelector Node labels for Test pod assignment
  # If set to, it takes priority over the `nodeSelector`
  nodeSelector: {}
  # tests.tolerations Tolerations for Test pod assignment
  # If set to, it takes priority over the `tolerations`
  tolerations: []
  ## Test container image parameters
  image:
    ## tests.image.repository test container image name
    repository: onlyoffice/docs-utils
    ## tests.image.tag test container image tag
    tag: 8.0.1-1
    ## tests.image.pullPolicy test container image pull policy
    pullPolicy: IfNotPresent
  ## Configure a Security Context for the Test container
  containerSecurityContext:
    ## tests.containerSecurityContext.enabled Enable security context for the Test container
    enabled: false
    ## tests.containerSecurityContext.runAsUser User ID for the Test container
    runAsUser: 101
    ## tests.containerSecurityContext.runAsGroup Group ID for the Test container
    runAsGroup: 101
    ## tests.containerSecurityContext.runAsNonRoot Require that the container will run with a user with UID other than 0
    runAsNonRoot: true
    ## tests.containerSecurityContext.allowPrivilegeEscalation Controls whether a process can gain more privileges than its parent process
    allowPrivilegeEscalation: false
    ## tests.containerSecurityContext.seccompProfile Defines the Seccomp profile for the Test container
    seccompProfile:
      type: RuntimeDefault
    ## tests.containerSecurityContext.capabilities Defines the privileges granted to the process
    capabilities:
      drop: ["ALL"]
  # test container resource requests and limits
  # ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # tests.resources.requests The requested resources for the test container
  # tests.resources.limits The resources limits for the test container
  resources:
    requests:
      memory: "256Mi"
      cpu: "200m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
